{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook to experiment with ways to quantify pec fin morphology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from ome_zarr.io import parse_url\n",
    "from ome_zarr.reader import Reader\n",
    "import napari\n",
    "import numpy as np\n",
    "from napari_animation import Animation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, load an image dataset along with nucleus masks inferred using cellpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to parse metadata\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nick/miniforge3/envs/napari-env/lib/python3.10/site-packages/ome_zarr/reader.py\", line 366, in __init__\n",
      "    rgb = [(int(color[i : i + 2], 16) / 255) for i in range(0, 6, 2)]\n",
      "  File \"/Users/nick/miniforge3/envs/napari-env/lib/python3.10/site-packages/ome_zarr/reader.py\", line 366, in <listcomp>\n",
      "    rgb = [(int(color[i : i + 2], 16) / 255) for i in range(0, 6, 2)]\n",
      "ValueError: invalid literal for int() with base 16: 're'\n",
      "no parent found for <ome_zarr.reader.Label object at 0x152a83dc0>: None\n"
     ]
    }
   ],
   "source": [
    "# set parameters\n",
    "filename = \"2022_12_22 HCR Sox9a Tbx5a Emilin3a_1.zarr\"\n",
    "readPath = \"/Users/nick/Dropbox (Cole Trapnell's Lab)/Nick/pecFin/HCR_Data/built_zarr_files_small/\" + filename\n",
    "readPathLabels = \"/Users/nick/Dropbox (Cole Trapnell's Lab)/Nick/pecFin/HCR_Data/built_zarr_files_small/\" + filename + \"labels\"\n",
    "level = 1\n",
    "\n",
    "#############\n",
    "# Main image\n",
    "#############\n",
    "\n",
    "# read the image data\n",
    "store = parse_url(readPath, mode=\"r\").store\n",
    "reader = Reader(parse_url(readPath))\n",
    "\n",
    "# nodes may include images, labels etc\n",
    "nodes = list(reader())\n",
    "\n",
    "# first node will be the image pixel data\n",
    "image_node = nodes[0]\n",
    "image_data = image_node.data\n",
    "\n",
    "#############\n",
    "# Labels\n",
    "#############\n",
    "\n",
    "# read the image data\n",
    "store_lb = parse_url(readPathLabels, mode=\"r\").store\n",
    "reader_lb = Reader(parse_url(readPathLabels))\n",
    "\n",
    "# nodes may include images, labels etc\n",
    "nodes_lb = list(reader_lb())\n",
    "\n",
    "# first node will be the image pixel data\n",
    "label_node = nodes_lb[1]\n",
    "label_data = label_node.data\n",
    "\n",
    "# extract key image attributes\n",
    "omero_attrs = image_node.root.zarr.root_attrs['omero']\n",
    "channel_metadata = omero_attrs['channels']  # list of channels and relevant info\n",
    "multiscale_attrs = image_node.root.zarr.root_attrs['multiscales']\n",
    "axis_names = multiscale_attrs[0]['axes']\n",
    "dataset_info = multiscale_attrs[0]['datasets']  # list containing scale factors for each axis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's visualize the masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimensions are not uniform. We want to account for this in the plot\n",
    "# pull second-smallest image and experiment\n",
    "im_3 = np.asarray(image_data[level])\n",
    "# calculate upper resolution limit for display\n",
    "res_upper = np.percentile(im_3[3, :, :, :], 99.999)\n",
    "# extract useful info\n",
    "scale_vec = multiscale_attrs[0][\"datasets\"][level][\"coordinateTransformations\"][0][\"scale\"]\n",
    "channel_names = [channel_metadata[i][\"label\"] for i in range(len(channel_metadata))]\n",
    "colormaps = [channel_metadata[i][\"color\"] for i in range(len(channel_metadata))]\n",
    "\n",
    "#viewer = napari.view_image(image_data[level], channel_axis=0, name=channel_names, colormap=colormaps, contrast_limits=[0, res_upper], scale=scale_vec)\n",
    "#labels_layer = viewer.add_labels(label_data[level], name='segmentation', scale=scale_vec)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Those are pretty complicated...lets try looking at only centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.measure import label, regionprops, regionprops_table\n",
    "\n",
    "label_array = np.asarray(label_data[level].compute())\n",
    "regions = regionprops(label_array)\n",
    "\n",
    "centroid_array = np.empty((len(regions), 3))\n",
    "for rgi, rg in enumerate(regions):\n",
    "    centroid_array[rgi, :] = rg.centroid "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot 3D scatter of centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'plotly'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[7], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mmatplotlib\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpyplot\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mplt\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mplotly\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mexpress\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mpx\u001B[39;00m\n\u001B[1;32m      4\u001B[0m fig \u001B[38;5;241m=\u001B[39m plt\u001B[38;5;241m.\u001B[39mfigure()\n\u001B[1;32m      5\u001B[0m ax \u001B[38;5;241m=\u001B[39m fig\u001B[38;5;241m.\u001B[39madd_subplot(projection\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m3d\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'plotly'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "ax.scatter(centroid_array[:, 0], centroid_array[:, 1], centroid_array[:, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
